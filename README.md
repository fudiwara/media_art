メディアアート制作プロジェクト用参考プログラム
---
Googleの[MediaPipe](https://ai.google.dev/edge/mediapipe/)の参考プログラムです。

MediaPipeはカメラからの映像や画像データを入力として複雑な処理をリアルタイムで動作させることができます。既存の機械学習モデルに対して、モデルの軽量化や推論の最適化によって、効率的に実行するために最適化されており、GPUが搭載されていない、あるいは性能が低めの環境でもある程度のリアルタイム処理が実装できるようになっています。

初期バージョンが2019年6月にリリースされており、2023年4月にリリースされたバージョン0.10.0から新しいインターフェイス(新API)に変わっています。Web上では初期インターフェイス(旧API)を紹介している記事が多く存在するため、実装したいタスクに応じて目的の情報か見極める必要があります。

とてもざっくりとした違いとして、旧APIは実装時にモデルファイルを意識する必要がありませんでした。MediaPipeが自動でモデルファイルをダウンロードし、アプリケーションに組み込むため、実装のハードルが低いというメリットがありました。一方で、カスタマイズ性が下がることにもなっていました。

一方で、新APIは、実装において利用するモデルのファイルを明示するため、公式サイト等から各機能のモデルファイルを事前にダウンロードしておく必要があります。一手間かかりますが、全体的に新APIの方が実装できる機能が充実しています。

公開しているプログラムのapi1_*は旧APIでのプログラムです。api2_*は新APIでのプログラムです。

#### 顔検出
##### api1_1mp_cam_face_det.py (旧)
##### api2_1mp_cam_face.py
内容にほぼ違いはないですが新APIの方が大きめに表示された顔を得意としているようです(スマホのセルフィー向け)。

#### 顔の特徴点検出
##### api1_2mp_cam_face_mesh.py (旧)
##### api2_2mp_cam_face_mesh.py
これも内容的な違いはないですが、モデルを変更した場合は新APIを使います。

#### 手・指検出
##### api1_3mp_cam_hand.py (旧)
##### api2_4mp_cam_hand.py
##### api2_5mp_cam_hand_fingertip.py
これも内容的な違いはないですが、旧APIでは映像のミラーリングの対応のしかたが異なるため手の左右について表示結果が逆になります。

#### 手のジェスチャー
##### api2_6mp_cam_hand_gesture.py
ジェスチャー以外の実装できる内容は手の検出に近いです。7種のハンドサインを識別できます。グー、チョキ、パーも含まれているのでじゃんけんもいけます。

#### セマンティックセグメンテーション
##### api1_4mp_cam_segmentation.py (旧)
##### api2_7mp_cam_segmentation.py
##### api2_8mp_cam_segmentation_anyParts.py
新APIで追加された機能が多いです。旧APIでは、人物-背景 および 髪-それ以外 という2種のモデルが用意されていましたが、新APIでは一つのモデルで、髪、顔、肌(顔以外の)、服、アクセサリと5種の領域に分割することができます。

#### ポーズ検出
##### api1_5mp_cam_pose.py (旧)
##### api2_9mp_cam_pose.py
検出できるポーズの内容に変更はないですが、旧APIでは検出対象が一人のみでした。

#### 一般物体検出
##### api2_3mp_cam_det_obj.py
MS COCOデータセットで学習した80種のオブジェクトの検出をすることができます。ですが、そこまで万能な性能ではありませんので利用時にはある程度の工夫が必要になります。